{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6a5d8681","cell_type":"markdown","source":"# **Machine Learning Project**","metadata":{}},{"id":"9d9be223","cell_type":"markdown","source":"In questa esercitazione metteremo assieme tutte le nozioni apprese dall'inizio del corso per risolvere un task specifico di machine learning.","metadata":{}},{"id":"cd9126f8","cell_type":"markdown","source":"### **Task: Semi-supervised classification**\n\nIl task che vogliamo risolvere è un task di classificazione, caratterizzato però dal fatto che solo una piccola parte dei dati che disponiamo possiede le annotazioni (label). Questa condizione è nota come `Semi-supervised learning`. \n\n### **Dataset**\n\nIl dataset che utilizzeremo sarà Fashion-MNIST, che contiene immagini di articoli di Zalando, composto da un training set di 60.000 campioni e test set con 10.000 campioni. Ogni campione è in scala di grigi e ha risoluzione 28x28. Il dataset è composto da 10 classi.\n","metadata":{}},{"id":"6c1b2838","cell_type":"markdown","source":"## **Pseudo-label**","metadata":{}},{"id":"4726ca22","cell_type":"markdown","source":"Lo **pseudo-labeling** è una tecnica utilizzata nell'ambito del *semi-supervised learning*. L'idea di base è quella di generare etichette \"artificiali\" (pseudo-etichette) per i dati non etichettati (unlabeled, \"U\"), in modo da utilizzarle durante il training del modello. Per generare queste etichette ci sono diverse strategie: nel contesto di questa esercitazione utilizzeremo un algoritmo di clustering (k-means).\n\nEcco i passaggi generali del processo di pseudo-labeling:\n\n1.  **Addestramento Iniziale**: Si addestra un algortimo di clustering sul set non etichettato (U) utilizzando un numero di cluster pari al numero di classi.\n2.  **Predizione su Dati Etichettati**: Utilizziamo l'algortimo addestrato al punto 1 per clusterizzare i dati etichettati (L), assegnandoli quindi ai cluster che abbiamo trovato durante l' addestramento iniziale.\n3.  **Mappare i cluster alle etichette**: Creiamo un mapping tra i cluster e le etichette, in modo da capire quale etichetta corrisponde allo specifico cluster. Per fare ciò assegniamo ad ogni cluster la vera label più frequente assegnata a quel cluster, sfruttando la funzione `mode`:\n\n```Python\nfrom scipy.stats import mode\nimport numpy as np\n\netichette_nel_cluster = np.array([0, 1, 1, 2, 1, 0, 1])\n\nrisultato_mode = mode(etichette_nel_cluster)\n\nprint(f\"Oggetto ModeResult: {risultato_mode}\") # Output: ModeResul(mode=1, count=4)\nprint(f\"Etichetta più frequente (moda): {risultato_mode.mode}\") # Output: (moda): 1\n\n# etichetta più frequente come singolo numero:\netichetta_predominante = risultato_mode.mode\nprint(f\"Etichetta predominante per questo cluster: {etichetta_predominante}\") # Output: 1\n```\n\n4.  **Estrazione pseudo-label**: Alla fine, la classe più presente in un cluster diventa l' etichetta scelta per tutti i campioni assegnati a quel cluster. \n\n\n**Vantaggi**:\n*   Permette di sfruttare la grande quantità di dati non etichettati, che altrimenti andrebbero sprecati.\n*   Può migliorare significativamente le prestazioni del modello rispetto all'addestramento con i soli dati etichettati, specialmente quando questi ultimi sono scarsi.","metadata":{}},{"id":"748cbb1a","cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.stats import mode # For majority voting\nfrom sklearn.neural_network import MLPClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.217721Z","iopub.status.idle":"2025-05-29T16:18:49.218164Z","shell.execute_reply.started":"2025-05-29T16:18:49.217912Z","shell.execute_reply":"2025-05-29T16:18:49.217931Z"}},"outputs":[],"execution_count":null},{"id":"671e368d","cell_type":"code","source":"# Nomi delle classi per Fashion-MNIST\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.219697Z","iopub.status.idle":"2025-05-29T16:18:49.220208Z","shell.execute_reply.started":"2025-05-29T16:18:49.219909Z","shell.execute_reply":"2025-05-29T16:18:49.219927Z"}},"outputs":[],"execution_count":null},{"id":"1a7b5d18","cell_type":"markdown","source":"### `load_and_preprocess_data()`\n\nIn questa funzione dovrete:\n\n* Scaricare il dataset.\n* Riordinare casualmente i dati.\n* Effettuare reshape.\n* Scalare i valori dei pixel all' intervallo [0,1].\n* Ridurre il numero di campioni a 10.000 per il train e 1.000 per il test.\n\nLa funzione dovrà ritornare nel seguente ordine:\n\n1. Il training set ridotto.\n2. Le etichette di train ridotte.\n3. Il test set ridotto.\n4. Le etichette di test ridotte.","metadata":{}},{"id":"8885ad81","cell_type":"code","source":"def load_and_preprocess_data():\n    \"\"\"Carica e pre-processa il dataset Fashion-MNIST.\"\"\"\n    np.random.seed(0)\n\n    # 1. Carica i dati\n    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n    # 2. Riordina casualmente i dati\n    indices = np.arange(x_train.shape[0])\n    \n    np.random.shuffle(indices)\n    x_train = x_train[indices]\n    y_train = y_train[indices]\n\n    #effettuo reshape \n    x_train = x_train.astype('float32')/255.0\n    x_test = x_test.astype('float32')/255.0\n\n    x_train_reduced = x_train[:8000]\n    x_test_reduced = x_test[:1000]\n    y_train_reduced = y_train[:8000]\n    y_test_reduced = y_test[:1000]\n    # 6. Ritorna i dati nel giusto ordine\n    return x_train_reduced, y_train_reduced, x_test_reduced, y_test_reduced\nload_and_preprocess_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.221708Z","iopub.status.idle":"2025-05-29T16:18:49.222106Z","shell.execute_reply.started":"2025-05-29T16:18:49.221917Z","shell.execute_reply":"2025-05-29T16:18:49.221935Z"}},"outputs":[],"execution_count":null},{"id":"7e4f4f2c","cell_type":"markdown","source":"### `apply_pca_and_scale`\n\nIn questa funzione dovrete:\n\n* Scalare il training set e il test set.\n* Applicare PCA con un numero di componenti specificato come parametro della funzione (o, equivalentemente, con una frazione desiderata della varianza espressa).\n* Stampare il numero di componenti.\n* Stampare la varianza espressa.\n\nLa funzione dovrà ritornare nel seguente ordine:\n\n1. Il training set trasformato con PCA.\n2. Il test set trasformato con PCA.","metadata":{}},{"id":"cf661359","cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef apply_pca_and_scale(x_train, x_test, n_components):\n\n    x_train = x_train.reshape(len(x_train), -1)\n    x_test = x_test.reshape(len(x_test), -1)\n\n    scaler = StandardScaler()\n    x_train_scaled = scaler.fit_transform(x_train)\n    x_test_scaled = scaler.transform(x_test)\n\n    pca = PCA(n_components=n_components, random_state=42)\n    x_train_pca = pca.fit_transform(x_train_scaled)\n    x_test_pca = pca.transform(x_test_scaled)\n\n    print(f\"PCA - Numero componenti: {pca.n_components_}\")\n    print(f\"PCA - Varianza spiegata totale: {np.sum(pca.explained_variance_ratio_):.4f}\")\n\n    return x_train_pca, x_test_pca","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.224550Z","iopub.status.idle":"2025-05-29T16:18:49.224964Z","shell.execute_reply.started":"2025-05-29T16:18:49.224817Z","shell.execute_reply":"2025-05-29T16:18:49.224832Z"}},"outputs":[],"execution_count":null},{"id":"c19d6064","cell_type":"markdown","source":"### `create_semi_supervised_split`\n\nIn questa funzione dovrete:\n\n* Splittare il training set in due insiemi, etichettato (L) e non etichettato (U) utilizzando  `train_test_split` con:\n\n`test_size`=`(1.0 - labeled_fraction)`\n\n* Stampare la shape del set etichettato.\n* Stampare la shape del set non etichettato.\n\nLa funzione deve ritornare nell seguente ordine:\n\n1. Il set etichettato.\n2. Le etichette del set etichettato.\n3. Il set non etichettato.\n4. Le etichette del set non etichettato. **N.B.** Queste etichette verranno utilizzate **SOLO** per valutare le pseudo-labels, non per l'addestramento.\n","metadata":{}},{"id":"8c868c74","cell_type":"code","source":"def create_semi_supervised_split(x_train_pca, y_train, labeled_fraction):\n    \n    # Split del training set\n    x_labeled, x_unlabeled, y_labeled, y_unlabeled = train_test_split(\n        x_train_pca, y_train,\n        test_size=(1.0 - labeled_fraction),\n        stratify=y_train,\n        random_state=0\n    )\n\n    # Stampa delle shape\n    print(f\"Set etichettato (L) shape: {x_labeled.shape}\")\n    print(f\"Set non etichettato (U) shape: {x_unlabeled.shape}\")\n\n    return x_labeled, y_labeled, x_unlabeled, y_unlabeled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.226219Z","iopub.status.idle":"2025-05-29T16:18:49.226586Z","shell.execute_reply.started":"2025-05-29T16:18:49.226395Z","shell.execute_reply":"2025-05-29T16:18:49.226406Z"}},"outputs":[],"execution_count":null},{"id":"4052846d","cell_type":"markdown","source":"### `get_pseudo_labels`\n\nIn questa funzione dovrete:\n\n* Istanziare un algoritmo di clustering (ad esempio, k-means).\n* Addestrare e predire i clustering sul set non etichettato.\n* Predire i clustering del set etichettato.\n* Mappare i cluster ad un etichetta, utilizzando per ogni cluster l'etichetta più presente, estraibile utilizzando la funzione `mode` presentata sopra.\n* Generare un array `pseudo_labels` assegnando a ogni campione del set non etichettato l'etichetta corrispondente al cluster a cui è stato assegnato.\n\nLa funzione deve ritornare:\n\n1. L' array `pseudo_labels`.","metadata":{}},{"id":"d6560820","cell_type":"code","source":"\ndef get_pseudo_labels(x_unlabeled, x_labeled, y_labeled, n_clusters=10):\n    \"\"\"Genera pseudo-labels usando clustering + majority voting.\"\"\"\n\n    # 1. Clustering sui dati non etichettati\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(x_unlabeled)\n      \n    # 2. Cluster assignments\n    cluster_assignments_unlabeled = kmeans.predict(x_unlabeled)\n    cluster_assignments_labeled = kmeans.predict(x_labeled)\n\n    # 3. Mappatura cluster → etichetta\n    cluster_to_true_label_map = {}\n    for k_idx in range(n_clusters):\n        # Trova indici dei dati etichettati assegnati a questo cluster\n        indices = np.where(cluster_assignments_labeled == k_idx)[0]\n        if len(indices) > 0:\n            labels = y_labeled[indices]\n            # Trova l’etichetta più frequente (moda)\n            most_common = mode(labels, keepdims=False).mode\n            cluster_to_true_label_map[k_idx] = most_common\n        else:\n            # Nessun dato etichettato in questo cluster\n            cluster_to_true_label_map[k_idx] = np.nan\n\n    # 4. Assegna pseudo-labels\n    pseudo_labels_list = []\n    for c_assign in cluster_assignments_unlabeled:\n        label = cluster_to_true_label_map.get(c_assign, np.nan)\n        pseudo_labels_list.append(label)\n\n    # 5. Converti in array\n    pseudo_labels = np.array(pseudo_labels_list)\n\n    return pseudo_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.227386Z","iopub.status.idle":"2025-05-29T16:18:49.227704Z","shell.execute_reply.started":"2025-05-29T16:18:49.227571Z","shell.execute_reply":"2025-05-29T16:18:49.227584Z"}},"outputs":[],"execution_count":null},{"id":"316409a5","cell_type":"markdown","source":"### `train_and_evaluate_classifier`\n\nIn questa funzione dovrete:\n\n* Rimuovere eventuali campioni con etichette NaN (potrebbero provenire da pseudo labels non mappate).\n* Istanziare il modello utilizzando `model_class` come oggetto e `classifier_args` come argomenti. Esempio:\n\n```Python\nmodel_class = MLPClassifier\nclassifier_args = {'max_iter': 200, 'hidden_layer_sizes': (100, 50)}\nmodel = model_class(**classifier_args)\n\n# Equivalente a:\nmodel = MLPClassifier(max_iter=200, hidden_layer_sizes=(100, 50))\n\n```\n\n* Allenare il modello sul training set a cui sono stati rimossi i campioni con etichette NaN.\n* Calcolare l' accuracy.\n* Stampare il `title`, che consiste nel titolo dell' esperimento eseguito. Questo perchè tale funzione verrà riutilizzata diverse volte per più set di dati. Un titolo ci permetterà di identificare quali risultati stiamo producendo.\n* Stampare l' accuracy.\n* Stampare il classification report.\n\nLa funzione deve ritornare:\n\n1. Il modello.\n","metadata":{}},{"id":"d4d5b673","cell_type":"code","source":"def train_and_evaluate_classifier(model_class, classifier_args, x_train, y_train, x_test, y_test, title=None, class_names_list=None):\n    valid_indices_train = ~np.isnan(y_train)\n    x_train_c = x_train[valid_indices_train]\n    y_train_c = y_train[valid_indices_train]\n\n    model = model_class(**classifier_args)\n    model.fit(x_train_c, y_train_c)\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{title} - Accuracy: {accuracy:.4f}\")\n\n    if class_names_list is not None:\n        from sklearn.metrics import classification_report\n        print(classification_report(y_test, y_pred, target_names=class_names_list))\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.229040Z","iopub.status.idle":"2025-05-29T16:18:49.229338Z","shell.execute_reply.started":"2025-05-29T16:18:49.229219Z","shell.execute_reply":"2025-05-29T16:18:49.229230Z"}},"outputs":[],"execution_count":null},{"id":"3a1c37dd","cell_type":"markdown","source":"### `main`\n\nIn questa funzione dovrete:\n\n* Utilizzare la funzione `load_and_preprocess_data` per caricare e pre-processare i dati.\n* Utilizzare la funzione `apply_pca_and_scale` per applicare scaling e PCA.\n* Utilizzare la funzione `create_semi_supervised_split` per dividere il train set in set etichettato e non etichettato.\n* Utilizzare la funzione `get_pseudo_labels` per calcoalre le pseudo labels sul set non etichettato.\n* Calcolare l' accuracy delle pseudo labels, cioè confrontarle con quelle vere in modo da vedere quanto sono accurate.\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati etichettati (L).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati non etichettati (U).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello sui dati etichettati (L) più quelli non etichettati (U).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello su tutto il dataset originale.","metadata":{}},{"id":"715e5f56","cell_type":"code","source":"def main(classifier_class, classifier_args, n_components_pca, labeled_fraction, n_clusters):\n    x_train, y_train, x_test, y_test = load_and_preprocess_data()\n\n    x_train_pca, x_test_pca = apply_pca_and_scale(x_train, x_test, n_components_pca)\n\n    x_etichettato, y_etichettato, x_nonetichettato, y_nonetichettato = create_semi_supervised_split(x_train_pca, y_train, labeled_fraction)\n\n    pseudo_labels = get_pseudo_labels(x_nonetichettato, x_etichettato, y_etichettato, n_clusters)\n\n    mask = ~np.isnan(pseudo_labels) \n    pseudo_accuracy = accuracy_score(y_nonetichettato[mask], pseudo_labels[mask])\n    print(f\"\\nAccuracy delle pseudo-labels: {pseudo_accuracy:.4f}\\n\")\n\n    print(\" Modello solo su dati etichettati :\")\n    train_and_evaluate_classifier(classifier_class, classifier_args, x_etichettato, y_etichettato, x_test_pca, y_test)\n\n    print(\"\\n Modello solo su pseudo-labels :\")\n    train_and_evaluate_classifier(classifier_class, classifier_args, x_nonetichettato[mask], pseudo_labels[mask], x_test_pca, y_test)\n\n    print(\"\\n Modello su dati etichettati e pseudo-labels :\")\n    x_combined = np.concatenate([x_etichettato, x_nonetichettato[mask]])\n    y_combined = np.concatenate([y_etichettato, pseudo_labels[mask]])\n    train_and_evaluate_classifier(classifier_class, classifier_args, x_combined, y_combined, x_test_pca, y_test)\n\n    # 9. Allena e valuta su tutto il train set originale (x_train_pca, y_train)\n    print(\"\\nModello su tutto il dataset supervisionato:\")\n    train_and_evaluate_classifier(classifier_class, classifier_args, x_train_pca, y_train, x_test_pca, y_test)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.231013Z","iopub.status.idle":"2025-05-29T16:18:49.231432Z","shell.execute_reply.started":"2025-05-29T16:18:49.231224Z","shell.execute_reply":"2025-05-29T16:18:49.231242Z"}},"outputs":[],"execution_count":null},{"id":"59e4e39c","cell_type":"markdown","source":"### **Utilizzare la funzione `main`**\n\nSpecifichiamo adesso un set di parametri richiesti dalla funzione main e utilizziamola. Nello specifico la funzione main ha bisogno di:\n\n* `classifier_class`: quale classificatore utilizzare, ad esempio `'MLPClassifier'`, `'LogisticRegression'` o altri visti in precedenza.\n* `classifier_args`: un dizionario contenente i parametri del classificatore scelto, ad esempio un `MLPClassifier` necessiterà del parametro `hidden_layer_sizes`. Dipendentemente da quale classificatore scegliete dovrete creare il dizionario.\n* `n_components_pca`: numero di componenti di PCA che vogliamo utilizzare. Se specifichiamo un valore compreso in [0, 1] questo verrà considerato come la percentuale di varianza che vogliamo mentenere.\n* `labeled_fraction`: percentuale di dati da usare come insieme etichettato. Si consiglia il valore 0.002 corrispondente allo 0.2%, cioè 16 immagini su 8000.\n* `n_clusters`: numero di cluster da utilizzare, nel nostro caso vogliamo che ci sia un cluster per ogni classe, quindi 10.\n\nInfine utilizziamo la funzione main.","metadata":{}},{"id":"beadf602","cell_type":"code","source":"# Parametri\nCLASSIFIER_CLASS = MLPClassifier  # Modello da usare, ad esempio LogisticRegression o SVC\nCLASSIFIER_ARGS = {\n    'max_iter': 20,\n    'hidden_layer_sizes': (200,200)  # Aumenta il numero di iterazioni per la convergenza\n}\nN_COMPONENTS_PCA = 0.95  # Mantiene il 95% della varianza spiegata, o un numero fisso es. 50\nLABELED_FRACTION = 0.002   # Frazione di dati da usare come insieme etichettato L\nN_CLUSTERS = 10          # Fashion-MNIST ha 10 classi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.232689Z","iopub.status.idle":"2025-05-29T16:18:49.233183Z","shell.execute_reply.started":"2025-05-29T16:18:49.232882Z","shell.execute_reply":"2025-05-29T16:18:49.232899Z"}},"outputs":[],"execution_count":null},{"id":"d9d2cb39","cell_type":"code","source":"main(\n    CLASSIFIER_CLASS,\n    CLASSIFIER_ARGS,\n    N_COMPONENTS_PCA,\n    LABELED_FRACTION,\n    N_CLUSTERS\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:18:49.234181Z","iopub.status.idle":"2025-05-29T16:18:49.234496Z","shell.execute_reply.started":"2025-05-29T16:18:49.234341Z","shell.execute_reply":"2025-05-29T16:18:49.234355Z"}},"outputs":[],"execution_count":null},{"id":"f28d4e71","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}